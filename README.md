# 対話型「データ分析＆可視化アシスタント」デモ

## 概要

LLMとの対話を通じて、社内データ（モック）を分析し、グラフを生成するデモプロジェクトです。MCP (Model Context Protocol) を活用し、LLMに直接データベースアクセスをさせることなく、定義されたツールを通じてデータ操作を実現します。

## 技術スタック

- **フロントエンド**: Next.js (TypeScript, App Router), Tailwind CSS
- **Webサーバー (MCPクライアント)**: FastAPI
- **MCPサーバー**: FastMCP
- **LLM**: OpenAI GPT-5
- **その他**: Docker, Docker Compose

## セットアップ手順

### 1. 前提条件

- Docker と Docker Compose がインストールされていること
- Node.js と npm (または yarn) がインストールされていること
- OpenAI APIキーを取得していること

### 2. 環境設定

プロジェクトのルートディレクトリに `.env` ファイルを作成し、ご自身のOpenAI APIキーを設定してください。

```
OPENAI_API_KEY="your_openai_api_key_here"
```

### 3. フロントエンドの依存関係インストール

`frontend` ディレクトリに移動し、以下のコマンドを実行します。

```bash
cd frontend
npm install
```
次に、フロントエンドの開発サーバーを起動します。
```bash
cd ..
docker compose up -d --build
```


5. アプリケーションへのアクセス
Webブラウザを開き、 http://localhost:3000 にアクセスしてください。チャット画面が表示されます。

### 使い方
チャット入力欄に、データ分析や可視化に関する指示を自然言語で入力してください。

質問例:
・2025年8月と9月の製品Aの売上データを棒グラフにして
・東京支社の顧客の年代を教えて
など。

このデモでは、簡易化のために一度に使用できるツールは1つだけです。
そのため、一度の応答でデータ取得＆グラフ生成などの複数ツールが必要なタスクを行うことはできません。
また、クエリによっては（それなりに高い確率で）エラーが発生する場合があります。